{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, accuracy_score\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 494\n",
      "Total labels: 494\n"
     ]
    }
   ],
   "source": [
    "# Define the root directory where your data is stored\n",
    "root_directory = \"dataset_2_final\"\n",
    "\n",
    "# Get the list of subdirectories (categories)\n",
    "subdirectories = [subdir for subdir in os.listdir(root_directory) if os.path.isdir(os.path.join(root_directory, subdir))]\n",
    "\n",
    "# Create lists to store image paths and corresponding labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each subdirectory (category)\n",
    "for label, subdirectory in enumerate(subdirectories):\n",
    "    # Construct the full path to the subdirectory\n",
    "    subdirectory_path = os.path.join(root_directory, subdirectory)\n",
    "\n",
    "    # Get a list of image files in the subdirectory\n",
    "    image_files = [os.path.join(subdirectory_path, filename) for filename in os.listdir(subdirectory_path) if filename.endswith('.jpg')]  # Adjust the file extension as needed\n",
    "    \n",
    "    # Append image paths and labels\n",
    "    image_paths.extend(image_files)\n",
    "    labels.extend([label] * len(image_files))\n",
    "\n",
    "\n",
    "# Now you have the image_paths and labels\n",
    "print(\"Total images:\", len(image_paths))\n",
    "print(\"Total labels:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom data generator that inherits from the Sequence class\n",
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size, image_size):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.num_samples = 4 * len(image_paths)\n",
    "        self.indices = np.arange(self.num_samples)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return int(np.ceil(self.num_samples / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Determine the range of indices for the current batch\n",
    "        batch_indices = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "\n",
    "\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "\n",
    "        # Iterate over indices in the current batch\n",
    "        for batch_index in batch_indices:\n",
    "\n",
    "            # Calculate the index of the original image and the piece index within it\n",
    "            image_index = batch_index // 4   # Divide by 4 to get original image index\n",
    "            piece_index = batch_index % 4    # Modulus 4 to get piece index\n",
    "\n",
    "            # Get the image path and original label for the current image\n",
    "            image_path = self.image_paths[image_index]\n",
    "            original_label = self.labels[image_index]\n",
    "            image_pieces = self.load_image(image_path)\n",
    "\n",
    "            # Load and split the image into pieces\n",
    "            piece = image_pieces[piece_index]\n",
    "            batch_images.append(piece)\n",
    "            batch_labels.append(original_label)\n",
    "\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "\n",
    "        return batch_images, batch_labels\n",
    "\n",
    "    def load_image(self, image_path):    \n",
    "\n",
    "        # Load the original image using Pillow\n",
    "        original_image = Image.open(image_path)\n",
    "        original_image_array = np.array(original_image)\n",
    "\n",
    "        # Split the original image into 4 pieces\n",
    "        h, w, c = original_image_array.shape\n",
    "        h_half, w_half = h // 2, w // 2\n",
    "       \n",
    "        image_pieces = [\n",
    "            original_image_array[:h_half, :w_half],\n",
    "            original_image_array[:h_half, w_half:],\n",
    "            original_image_array[h_half:, :w_half],\n",
    "            original_image_array[h_half:, w_half:]\n",
    "        ]\n",
    "        \n",
    "        # Resize the image pieces and provide the shape of the output\n",
    "        resized_images = [tf.image.resize(piece, self.image_size) for piece in image_pieces]\n",
    "\n",
    "        #Shape of resized image list\n",
    "        #print(np.array(resized_images).shape)    \n",
    "        \n",
    "        return resized_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 16\n",
    "image_size = (380, 380)  # Adjust the image size based on your model's input requirements\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(train_paths, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create data generators for training, validation, and test sets\n",
    "train_generator = CustomDataGenerator(train_paths, train_labels, batch_size, image_size)\n",
    "val_generator = CustomDataGenerator(val_paths, val_labels, batch_size, image_size)\n",
    "test_generator = CustomDataGenerator(test_paths, test_labels, batch_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(hp):\n",
    "\n",
    "    base_model = EfficientNetB4(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "    # Introduce a layer of data augmentation\n",
    "    data_augmentation = Sequential([\n",
    "        preprocessing.RandomRotation(0.2),\n",
    "        preprocessing.RandomFlip(\"horizontal\"),\n",
    "        preprocessing.RandomZoom(0.2),\n",
    "        preprocessing.RandomContrast(0.2),\n",
    "        preprocessing.RandomTranslation(0.2, 0.2),\n",
    "        preprocessing.RandomHeight(0.2),\n",
    "        preprocessing.RandomWidth(0.2),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Freeze all layers in the base model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    # Unfreeze the last 10 layers in the base model for fine-tuning\n",
    "    for layer in base_model.layers[-10:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Capa de entradas\n",
    "    entradas = layers.Input((380, 380, 3))\n",
    "    # Capa de augmentation\n",
    "    x = data_augmentation(entradas)\n",
    "    # Pass the augmented images through the base model\n",
    "    x = base_model(x)\n",
    "\n",
    "    # Tune the number of units in the dense layer\n",
    "    hp_units = hp.Int('units', min_value=128, max_value=512, step=128)\n",
    "\n",
    "    x = layers.Dense(units=hp_units, activation='relu')(x)\n",
    "    # Add another dense layer\n",
    "    salidas = layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=entradas, outputs=salidas)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log'))\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from random_search\\mnist_tuning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the RandomSearch tuner\n",
    "tuner = RandomSearch(\n",
    "\n",
    "    create_keras_model,  # Function to build the model\n",
    "    objective='val_accuracy',  # Metric to optimize\n",
    "    max_trials=5,  # Number of hyperparameter combinations to try\n",
    "    directory='random_search',  # Directory to store results\n",
    "    project_name='mnist_tuning'  # Name of the tuning project\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(train_generator, epochs=5, validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in random_search\\mnist_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.0002567242062548327\n",
      "Score: 0.6139240264892578\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.00020073323630288932\n",
      "Score: 0.5917721390724182\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.00019600097198800183\n",
      "Score: 0.547468364238739\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "learning_rate: 0.0063316719848339085\n",
      "Score: 0.503164529800415\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "learning_rate: 0.00846883575748356\n",
      "Score: 0.452531635761261\n",
      "Results summary\n",
      "Results in random_search\\mnist_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0 summary\n",
      "Hyperparameters:\n",
      "units: 384\n",
      "learning_rate: 0.0002567242062548327\n",
      "Score: 0.6139240264892578\n",
      "\n",
      "Trial 2 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.00020073323630288932\n",
      "Score: 0.5917721390724182\n",
      "\n",
      "Trial 3 summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.00019600097198800183\n",
      "Score: 0.547468364238739\n",
      "\n",
      "Trial 4 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "learning_rate: 0.0063316719848339085\n",
      "Score: 0.503164529800415\n",
      "\n",
      "Trial 1 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "learning_rate: 0.00846883575748356\n",
      "Score: 0.452531635761261\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 380, 380, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb4 (Functional)  (None, 1792)              17673823  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 384)               688512    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 2695      \n",
      "=================================================================\n",
      "Total params: 18,365,030\n",
      "Trainable params: 3,006,471\n",
      "Non-trainable params: 15,358,559\n",
      "_________________________________________________________________\n",
      "Best model summary: \n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 380, 380, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "efficientnetb4 (Functional)  (None, 1792)              17673823  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 384)               688512    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 2695      \n",
      "=================================================================\n",
      "Total params: 18,365,030\n",
      "Trainable params: 3,006,471\n",
      "Non-trainable params: 15,358,559\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "#Print a graph of the search\n",
    "tuner.results_summary()\n",
    "\n",
    "\n",
    "#Print all available information about the grid search\n",
    "tuner.results_summary()\n",
    "\n",
    "\n",
    "# Build and compile the best model\n",
    "best_model = tuner.hypermodel.build(best_hyperparameters)\n",
    "\n",
    "print(\"Best model summary: \")\n",
    "best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
