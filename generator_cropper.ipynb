{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to your dataset directory\n",
    "\n",
    "dataset_dir = \"dataset_2_final\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the ImageDataGenerator with data augmentation and cropping\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Splitting the dataset into training and validation sets\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom data generator to generate four cropped images per input image\n",
    "\n",
    "def custom_data_generator(data_generator, steps_per_epoch):\n",
    "    i = 0  # Initialize the batch counter\n",
    "    while True:  # Create an infinite loop for the generator\n",
    "        batch_images = []\n",
    "        batch_labels = []\n",
    "        for images, labels in data_generator:\n",
    "            for image, label in zip(images, labels):\n",
    "                # Crop the image into four quadrants\n",
    "                height, width = image.shape[0], image.shape[1]\n",
    "                half_height, half_width = height // 2, width // 2\n",
    "                quadrants = [\n",
    "                    image[:half_height, :half_width, :],\n",
    "                    image[:half_height, half_width:, :],\n",
    "                    image[half_height:, :half_width, :],\n",
    "                    image[half_height:, half_width:, :],\n",
    "                ]\n",
    "                batch_images.extend(quadrants)\n",
    "                batch_labels.extend([label] * 4)  # Fix the label repetition for each quadrant\n",
    "\n",
    "                # Check if the batch is large enough\n",
    "                if len(batch_images) >= batch_size:  # Assuming you have a 'batch_size' variable defined\n",
    "                    break\n",
    "\n",
    "            # Check if we have generated enough batches (steps_per_epoch)\n",
    "            if i >= steps_per_epoch:\n",
    "                return  # End the generator\n",
    "\n",
    "        batch_images = np.stack(batch_images)\n",
    "        batch_labels = np.stack(batch_labels)\n",
    "        yield batch_images, batch_labels\n",
    "\n",
    "        i += 1  # Increment the batch counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (300, 300)\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 423 images belonging to 7 classes.\n",
      "Found 102 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the training dataset using image_dataset_from_directory\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  # For integer labels\n",
    "    shuffle=True,\n",
    "    subset='training',    # Selecting the training set\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "# Load the validation dataset using image_dataset_from_directory\n",
    "val_ds = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  # For integer labels\n",
    "    shuffle=False,        # No need to shuffle the validation set\n",
    "    subset='validation',  # Selecting the validation set\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "# Check the number of classes in your dataset\n",
    "num_classes = len(train_ds.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the EfficientNetB3 model\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=image_size + (3,))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the custom data generator\n",
    "epochs = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of training and validation images\n",
    "total_train_images = len(train_ds.filenames)\n",
    "total_val_images = len(val_ds.filenames)\n",
    "\n",
    "# Calculate steps_per_epoch and validation_steps\n",
    "steps_per_epoch = total_train_images // batch_size\n",
    "validation_steps = total_val_images // batch_size\n",
    "\n",
    "# If there are any remaining images that do not fit in a full batch, add one more step\n",
    "if total_train_images % batch_size != 0:\n",
    "    steps_per_epoch += 1\n",
    "if total_val_images % batch_size != 0:\n",
    "    validation_steps += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "print(total_train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model using the custom data generator\n",
    "model.fit(\n",
    "    custom_data_generator(train_ds, steps_per_epoch),  # Pass the custom data generator here\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
