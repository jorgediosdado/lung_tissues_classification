{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to your dataset directory\n",
    "dataset_dir = \"dataset_2_final\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 423 images belonging to 7 classes.\n",
      "Found 102 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set image and batch size\n",
    "image_size = (300, 300)\n",
    "batch_size = 4\n",
    "\n",
    "# Create the ImageDataGenerator with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # Splitting the dataset into training and validation sets\n",
    ")\n",
    "\n",
    "# Load the training dataset using image_dataset_from_directory\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  # For integer labels\n",
    "    shuffle=True,\n",
    "    subset='training',    # Selecting the training set\n",
    "    seed=1337\n",
    ")\n",
    "\n",
    "# Load the validation dataset using image_dataset_from_directory\n",
    "val_ds = train_datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse',  # For integer labels\n",
    "    shuffle=False,        # No need to shuffle the validation set\n",
    "    subset='validation',  # Selecting the validation set\n",
    "    seed=1337\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "# Check the number of classes in your dataset\n",
    "num_classes = len(train_ds.class_indices)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNetB0: Image input size is (224, 224, 3)\n",
    "EfficientNetB1: Image input size is (240, 240, 3)\n",
    "EfficientNetB2: Image input size is (260, 260, 3)\n",
    "EfficientNetB3: Image input size is (300, 300, 3)\n",
    "EfficientNetB4: Image input size is (380, 380, 3)\n",
    "EfficientNetB5: Image input size is (456, 456, 3)\n",
    "EfficientNetB6: Image input size is (528, 528, 3)\n",
    "EfficientNetB7: Image input size is (600, 600, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the EfficientNetB3 model\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=image_size + (3,))\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "predictions = layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "106/106 [==============================] - 71s 664ms/step - loss: 0.7817 - accuracy: 0.7258 - val_loss: 2.3674 - val_accuracy: 0.4902\n",
      "Epoch 2/60\n",
      "106/106 [==============================] - 69s 653ms/step - loss: 0.7571 - accuracy: 0.7565 - val_loss: 1.9487 - val_accuracy: 0.3824\n",
      "Epoch 3/60\n",
      "106/106 [==============================] - 69s 651ms/step - loss: 0.7303 - accuracy: 0.7636 - val_loss: 1.6610 - val_accuracy: 0.5392\n",
      "Epoch 4/60\n",
      "106/106 [==============================] - 70s 657ms/step - loss: 0.6214 - accuracy: 0.7849 - val_loss: 3.1823 - val_accuracy: 0.4510\n",
      "Epoch 5/60\n",
      "106/106 [==============================] - 69s 648ms/step - loss: 0.6579 - accuracy: 0.7565 - val_loss: 1.3529 - val_accuracy: 0.5588\n",
      "Epoch 6/60\n",
      "106/106 [==============================] - 69s 652ms/step - loss: 0.7108 - accuracy: 0.7589 - val_loss: 2.3286 - val_accuracy: 0.4608\n",
      "Epoch 7/60\n",
      "106/106 [==============================] - 69s 652ms/step - loss: 0.6938 - accuracy: 0.7447 - val_loss: 1.6883 - val_accuracy: 0.5196\n",
      "Epoch 8/60\n",
      "106/106 [==============================] - 69s 648ms/step - loss: 0.7321 - accuracy: 0.7612 - val_loss: 1.6940 - val_accuracy: 0.5392\n",
      "Epoch 9/60\n",
      "106/106 [==============================] - 69s 647ms/step - loss: 0.6008 - accuracy: 0.7896 - val_loss: 2.1334 - val_accuracy: 0.5490\n",
      "Epoch 10/60\n",
      "106/106 [==============================] - 70s 659ms/step - loss: 0.5601 - accuracy: 0.7943 - val_loss: 1.4202 - val_accuracy: 0.6078\n",
      "Epoch 11/60\n",
      "106/106 [==============================] - 69s 649ms/step - loss: 0.5705 - accuracy: 0.8251 - val_loss: 1.3899 - val_accuracy: 0.5686\n",
      "Epoch 12/60\n",
      "106/106 [==============================] - 69s 651ms/step - loss: 0.5383 - accuracy: 0.8203 - val_loss: 1.5095 - val_accuracy: 0.6078\n",
      "Epoch 13/60\n",
      "106/106 [==============================] - 46s 432ms/step - loss: 0.6044 - accuracy: 0.7872 - val_loss: 1.7306 - val_accuracy: 0.5882\n",
      "Epoch 14/60\n",
      "106/106 [==============================] - 45s 423ms/step - loss: 0.4467 - accuracy: 0.8487 - val_loss: 1.6296 - val_accuracy: 0.5588\n",
      "Epoch 15/60\n",
      "106/106 [==============================] - 44s 414ms/step - loss: 0.4504 - accuracy: 0.8274 - val_loss: 2.3273 - val_accuracy: 0.5196\n",
      "Epoch 16/60\n",
      "106/106 [==============================] - 44s 417ms/step - loss: 0.6484 - accuracy: 0.7991 - val_loss: 1.3393 - val_accuracy: 0.6275\n",
      "Epoch 17/60\n",
      "106/106 [==============================] - 45s 418ms/step - loss: 0.4334 - accuracy: 0.8747 - val_loss: 2.0002 - val_accuracy: 0.5098\n",
      "Epoch 18/60\n",
      "106/106 [==============================] - 44s 414ms/step - loss: 0.4467 - accuracy: 0.8345 - val_loss: 1.4116 - val_accuracy: 0.6176\n",
      "Epoch 19/60\n",
      "106/106 [==============================] - 44s 415ms/step - loss: 0.5505 - accuracy: 0.7967 - val_loss: 1.6650 - val_accuracy: 0.5490\n",
      "Epoch 20/60\n",
      "106/106 [==============================] - 44s 417ms/step - loss: 0.5161 - accuracy: 0.8487 - val_loss: 2.2175 - val_accuracy: 0.4216\n",
      "Epoch 21/60\n",
      "106/106 [==============================] - 44s 415ms/step - loss: 0.4127 - accuracy: 0.8558 - val_loss: 1.9200 - val_accuracy: 0.5784\n",
      "Epoch 22/60\n",
      "106/106 [==============================] - 44s 415ms/step - loss: 0.4321 - accuracy: 0.8534 - val_loss: 1.1804 - val_accuracy: 0.6373\n",
      "Epoch 23/60\n",
      "106/106 [==============================] - 44s 418ms/step - loss: 0.4406 - accuracy: 0.8534 - val_loss: 4.7925 - val_accuracy: 0.4510\n",
      "Epoch 24/60\n",
      "106/106 [==============================] - 44s 414ms/step - loss: 0.4652 - accuracy: 0.8345 - val_loss: 1.9511 - val_accuracy: 0.5098\n",
      "Epoch 25/60\n",
      "106/106 [==============================] - 44s 413ms/step - loss: 0.3962 - accuracy: 0.8629 - val_loss: 1.6762 - val_accuracy: 0.5882\n",
      "Epoch 26/60\n",
      "106/106 [==============================] - 44s 414ms/step - loss: 0.3865 - accuracy: 0.8747 - val_loss: 1.6512 - val_accuracy: 0.6078\n",
      "Epoch 27/60\n",
      "106/106 [==============================] - 44s 415ms/step - loss: 0.3577 - accuracy: 0.8865 - val_loss: 1.4995 - val_accuracy: 0.6275\n",
      "Epoch 28/60\n",
      "106/106 [==============================] - 44s 414ms/step - loss: 0.4613 - accuracy: 0.8511 - val_loss: 1.3417 - val_accuracy: 0.5490\n",
      "Epoch 29/60\n",
      "106/106 [==============================] - 44s 414ms/step - loss: 0.3785 - accuracy: 0.8723 - val_loss: 1.5886 - val_accuracy: 0.6275\n",
      "Epoch 30/60\n",
      "106/106 [==============================] - 44s 415ms/step - loss: 0.3390 - accuracy: 0.8960 - val_loss: 2.2121 - val_accuracy: 0.6078\n",
      "Epoch 31/60\n",
      "106/106 [==============================] - 44s 415ms/step - loss: 0.2974 - accuracy: 0.8865 - val_loss: 2.5107 - val_accuracy: 0.5490\n",
      "Epoch 32/60\n",
      "106/106 [==============================] - 44s 414ms/step - loss: 0.3788 - accuracy: 0.8771 - val_loss: 1.6278 - val_accuracy: 0.5784\n",
      "Epoch 33/60\n",
      "106/106 [==============================] - 45s 422ms/step - loss: 0.3683 - accuracy: 0.8747 - val_loss: 1.8078 - val_accuracy: 0.5098\n",
      "Epoch 34/60\n",
      "106/106 [==============================] - 46s 428ms/step - loss: 0.3234 - accuracy: 0.8936 - val_loss: 1.3766 - val_accuracy: 0.6275\n",
      "Epoch 35/60\n",
      "106/106 [==============================] - 46s 428ms/step - loss: 0.3889 - accuracy: 0.8842 - val_loss: 2.0736 - val_accuracy: 0.5098\n",
      "Epoch 36/60\n",
      "106/106 [==============================] - 46s 429ms/step - loss: 0.3285 - accuracy: 0.8842 - val_loss: 1.9617 - val_accuracy: 0.5294\n",
      "Epoch 37/60\n",
      "106/106 [==============================] - 46s 428ms/step - loss: 0.4144 - accuracy: 0.8298 - val_loss: 4.4350 - val_accuracy: 0.3431\n",
      "Epoch 38/60\n",
      "106/106 [==============================] - 45s 419ms/step - loss: 0.3902 - accuracy: 0.8652 - val_loss: 1.9960 - val_accuracy: 0.5000\n",
      "Epoch 39/60\n",
      "106/106 [==============================] - 46s 428ms/step - loss: 0.2950 - accuracy: 0.8983 - val_loss: 2.1865 - val_accuracy: 0.4902\n",
      "Epoch 40/60\n",
      "106/106 [==============================] - 46s 433ms/step - loss: 0.2174 - accuracy: 0.9267 - val_loss: 2.0890 - val_accuracy: 0.5882\n",
      "Epoch 41/60\n",
      "106/106 [==============================] - 46s 432ms/step - loss: 0.2687 - accuracy: 0.9054 - val_loss: 1.1105 - val_accuracy: 0.6176\n",
      "Epoch 42/60\n",
      "106/106 [==============================] - 46s 431ms/step - loss: 0.3948 - accuracy: 0.8771 - val_loss: 1.7099 - val_accuracy: 0.6176\n",
      "Epoch 43/60\n",
      "106/106 [==============================] - 46s 432ms/step - loss: 0.2167 - accuracy: 0.9149 - val_loss: 1.6445 - val_accuracy: 0.6471\n",
      "Epoch 44/60\n",
      "106/106 [==============================] - 46s 431ms/step - loss: 0.2181 - accuracy: 0.9243 - val_loss: 2.1092 - val_accuracy: 0.5980\n",
      "Epoch 45/60\n",
      "106/106 [==============================] - 46s 429ms/step - loss: 0.2622 - accuracy: 0.8889 - val_loss: 1.8056 - val_accuracy: 0.5392\n",
      "Epoch 46/60\n",
      "106/106 [==============================] - 45s 427ms/step - loss: 0.2558 - accuracy: 0.9102 - val_loss: 2.6477 - val_accuracy: 0.5000\n",
      "Epoch 47/60\n",
      "106/106 [==============================] - 45s 420ms/step - loss: 0.2712 - accuracy: 0.9102 - val_loss: 1.6139 - val_accuracy: 0.5490\n",
      "Epoch 48/60\n",
      "106/106 [==============================] - 44s 415ms/step - loss: 0.1871 - accuracy: 0.9362 - val_loss: 1.4690 - val_accuracy: 0.6471\n",
      "Epoch 49/60\n",
      "106/106 [==============================] - 45s 424ms/step - loss: 0.2920 - accuracy: 0.9007 - val_loss: 2.0982 - val_accuracy: 0.5980\n",
      "Epoch 50/60\n",
      "106/106 [==============================] - 47s 436ms/step - loss: 0.4893 - accuracy: 0.8582 - val_loss: 2.0843 - val_accuracy: 0.5686\n",
      "Epoch 51/60\n",
      "106/106 [==============================] - 46s 434ms/step - loss: 0.2266 - accuracy: 0.9243 - val_loss: 2.0059 - val_accuracy: 0.5784\n",
      "Epoch 52/60\n",
      "106/106 [==============================] - 45s 426ms/step - loss: 0.2555 - accuracy: 0.9125 - val_loss: 2.5557 - val_accuracy: 0.4902\n",
      "Epoch 53/60\n",
      "106/106 [==============================] - 46s 428ms/step - loss: 0.2779 - accuracy: 0.8960 - val_loss: 2.5947 - val_accuracy: 0.5784\n",
      "Epoch 54/60\n",
      "106/106 [==============================] - 45s 427ms/step - loss: 0.2769 - accuracy: 0.8960 - val_loss: 2.7161 - val_accuracy: 0.4706\n",
      "Epoch 55/60\n",
      "106/106 [==============================] - 46s 432ms/step - loss: 0.2215 - accuracy: 0.9243 - val_loss: 2.8181 - val_accuracy: 0.5294\n",
      "Epoch 56/60\n",
      "106/106 [==============================] - 52s 486ms/step - loss: 0.3356 - accuracy: 0.8936 - val_loss: 2.4311 - val_accuracy: 0.5294\n",
      "Epoch 57/60\n",
      "106/106 [==============================] - 47s 442ms/step - loss: 0.1759 - accuracy: 0.9362 - val_loss: 1.7701 - val_accuracy: 0.5784\n",
      "Epoch 58/60\n",
      "106/106 [==============================] - 45s 421ms/step - loss: 0.2067 - accuracy: 0.9291 - val_loss: 1.7396 - val_accuracy: 0.6667\n",
      "Epoch 59/60\n",
      "106/106 [==============================] - 45s 419ms/step - loss: 0.2459 - accuracy: 0.9149 - val_loss: 2.5218 - val_accuracy: 0.5588\n",
      "Epoch 60/60\n",
      "106/106 [==============================] - 44s 417ms/step - loss: 0.1984 - accuracy: 0.9362 - val_loss: 1.6312 - val_accuracy: 0.6569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18f5d020550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 60\n",
    "steps_per_epoch = len(train_ds)\n",
    "validation_steps = len(val_ds)\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
